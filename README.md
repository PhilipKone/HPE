# Human Pose Estimation Project

## Overview

This project focuses on research and implementation of bottom-up human pose estimation, with an emphasis on adaptive, scale-aware heatmap generation and integration with state-of-the-art frameworks. It combines literature review, code experiments, and workflow diagrams to support experimentation and reproducible research.

## Project Structure

- **simple_bottom_up_pose.py**: Main Python script for adaptive heatmap generation, visualization, and prototyping.
- **articles/**: Research articles, tables, and supporting materials organized by research objectives.
- **external_repos/**: Cloned external repositories (e.g., HRNet, HigherHRNet, SWAHR, Scale-sensitive-Heatmap) for reference and code adaptation.
- **Markdown Files**:
  - `Human Pose Estimation Workflow.md`: Step-by-step workflow.
  - `Enhancing_Bottom_Up_Human_Pose_Estimation.md`: Pipeline improvements.
  - `Literature_Review.md`: Key research and findings.
  - `relevant_articles_comprehensive.md`: Curated article list.
  - `research_objectives_articles.md`: Research objectives and mapped articles.
- **.puml files**: PlantUML diagrams for visualizing frameworks and pipelines.

## Getting Started

1. **Review Documentation**: Start with the markdown files for workflow, literature review, and research objectives.
2. **Run Adaptive Heatmap Demo**:
   - Ensure Python 3.8+ is installed.
   - Install requirements: `pip install numpy matplotlib`
   - Run: `python simple_bottom_up_pose.py` to generate and visualize adaptive heatmaps.
3. **Explore External Repos**: Reference or adapt code from `external_repos/` for advanced experiments or integration with frameworks like HRNet or SWAHR.
4. **Visualize Diagrams**: Use PlantUML to render `.puml` files:
   ```bash
   java -jar plantuml.jar -tpng <diagram>.puml
   ```
5. **Browse Research**: See the `articles/` directory for grouped research, tables, and supporting documents by objective.

## Requirements

- Python 3.8+ (for .py scripts)
- numpy, matplotlib (for visualization)
- PlantUML (for diagram rendering)

## Contribution

Contributions are welcome! Add new research articles, code experiments, or update documentation to support ongoing research in human pose estimation.

## Example Visualization

Below are examples of adaptive, scale-aware heatmaps generated by the pipeline:

**Single Person, 3 Keypoints (Demo):**

![Adaptive Heatmap Example 1](results/Figure_1.png)

**Single Person, Synthetic Full 17 Keypoints (COCO Order):**

![Adaptive Heatmap Example 2](results/Figure_2.png)

**COCO Keypoints Heatmap Demo:**

![COCO Heatmap Example](results/Figure_3.png)

**COCO Keypoints Overlay Demo:**

![COCO Keypoints Overlay Example](results/Figure_4.png)

---

## Algorithmic Complexity Analysis: Batch Processing in `coco_heatmap_demo.py`

### Step-by-Step Analysis

1. **Input Size (N):**
   - Let N be the number of images to process from the COCO dataset.

2. **Main Loop:**
   - For batch processing, the code would iterate over all N images:
     ```python
     for image in images:  # N images
         process(image)
     ```

3. **Per-Image Processing:**
   - For each image, the following steps are performed:
     - Load the image and corresponding keypoints (O(1) per image, assuming constant image/keypoint size).
     - Scale keypoints and generate heatmaps (O(K × R²)), where K is the number of keypoints (17 for COCO) and R is the heatmap resolution (e.g., 64x64).
     - Visualization and plotting (O(K × R²) for heatmap generation and display).

4. **Total Complexity:**
   - For N images, each with K keypoints and heatmap resolution R, the total complexity is:
     - **O(N × K × R²)**
   - For typical values: K=17, R=64, so the dominant term is linear in N (number of images).

5. **Findings:**
   - **Time Complexity:** O(N × K × R²)
     - Linear with respect to the number of images (N), keypoints (K), and quadratic with respect to heatmap resolution (R).
   - **Space Complexity:**
     - Per image: O(K × R²) for storing heatmaps.
     - For batch processing, total space depends on whether all heatmaps are stored at once or processed sequentially.
   - **Parallelization:**
     - If using vectorized or parallel batch operations, the wall-clock time may decrease, but the total computational complexity remains O(N × K × R²).

### Summary Table
| Variable | Meaning                        | Actual Value |
|----------|---------------------------------|--------------|
| N        | Number of images                | 5000         |
| K        | Number of keypoints per annotation | 17        |
| R        | Heatmap resolution (R x R)      | 64           |

**COCO Keypoint Encoding Details:**
- In the COCO dataset, each person annotation contains a `keypoints` field with 51 values.
- Each keypoint is encoded as three consecutive values: (x, y, v), where:
  - x: x-coordinate
  - y: y-coordinate
  - v: visibility flag (0: not labeled, 1: labeled but not visible, 2: labeled and visible)
- Therefore, 51 values / 3 = 17 keypoints per annotation, which matches the COCO human pose standard.

**Heatmap Resolution Details:**
- In the code, the heatmap resolution variable `output_res` is set to 64:
  ```python
  output_res = 64  # Define this before using it
  ```
- This means each generated heatmap is 64 x 64 pixels.

**Conclusion:**
- The batch processing algorithm in `coco_heatmap_demo.py` scales linearly with the number of images and keypoints, and quadratically with the heatmap resolution. Optimization strategies (e.g., batching, parallelism) can reduce wall-clock time but do not change the overall complexity.

For detailed workflows and research context, refer to the included markdown files and articles. For adaptive heatmap generation and visualization, see `simple_bottom_up_pose.py`.
